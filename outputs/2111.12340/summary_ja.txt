
概要：本論文では、サッカーRLエージェントのプレイスタイルの特徴と、トレーニング中にどのように戦略が発展する可能性があるかを検証している。深層強化学習（RL）法を用いて、幅広い用途に秀でたエージェントを開発し、ソーシャルネットワーク分析（SNA）を適用して、シミュレーション環境の利用から何が学べるかを探っている。その結果、エージェントの競争力とSNAの各種指標には強い相関があり、RLエージェントのプレイスタイルの側面は、エージェントの競争力が高まるにつれて現実世界のサッカー選手と似てくることが判明しました。

実験Google Research Football のシミュレーション環境において，プロキシマルポリシー最適化を用いて，内蔵のイージーレベル，ミディアムレベル，ハードレベルのボットに対して 5000 万タイムス テップのトレーニングを実施した．エージェントのランク付けには TrueSkill ランキングシステムを使用し、選手が行ったパスの総数に基づいてページランクを計算した。プレイ特性を分析するための指標として，パス数/ショット数，近さ，間 隔，ページランクなどのソーシャルネットワーク分析指標を用いた．その結果、「総ショット数」と「betweenness（平均値）」は TrueSkill のランキングと強い正の相関があり、全体として最も相関が大きい指標は、ネットワーク内の最小値で集計したページランクであることが判明した。

さらに読むサッカーにおけるRLの応用について詳しく知りたい方は、五木（1995）の論文「Robot Soccer」とWunsch（2015）の論文「Reinforcement Learning for Robot Soccer」がお勧めの文献です。

用語解説はこちら
- Deep Reinforcement Learning（DRL）。従来の強化学習セットアップとディープニューラルネットワークを組み合わせたRLのサブセット
- 近位政策最適化(PPO)。Google Research Footballをプレイするエージェントのポリシーを学習するために使用されるアルゴリズム
- Social Network Analysis (SNA)。協調型RLエージェントの知能を分析し、その特徴を実世界のデータと比較するために使用される手法
- TrueSkill Ranking System（トゥルースキルランキングシステム）。ラウンドロビン方式によるエージェントのランキングシステム